<!DOCTYPE html>
<html lang="en">

  <head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <title>
    
      Grit & Grid Search &middot; A Data Science Blog
    
  </title>

  <link rel="stylesheet" href="/styles.css">
  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="/public/favicon.ico">
  <link rel="alternate" type="application/atom+xml" title="Grit & Grid Search" href="/atom.xml">
</head>


  <body>

    <div class="container content">
      <header class="masthead">
        <h3 class="masthead-title">
          <a href="/" title="Home">Grit & Grid Search</a>
          <small>A Data Science Blog:</small><br>
          
          &nbsp;&nbsp;&nbsp;
          <small><a href="/about">About</a></small>
          
          &nbsp;&nbsp;&nbsp;
          <small><a href="/archive">Archive</a></small>
          
          &nbsp;&nbsp;&nbsp;
          <small><a href="/index.html">Feed</a></small>
          
        </h3>
      </header>

      <main>
      <div class="posts">
  
  <article class="post">
    <h1 class="post-title">
      <a href="/2019/04/30/DecadeStyles/">
        DecadeStyles
      </a>
    </h1>
    
    <time datetime="2019-04-30T00:00:00-07:00" class="post-date">30 Apr 2019</time>
    
    <hr />
<h2 id="overview">Overview</h2>
<p>For this task, I wanted to build a clothing style classifier by decade. I could not find an existing dataset labeling attire style by decade, so I built one manually from Google images. Once this process was complete, I used transfer learning on a pre-trained deep-learning model to build my classifier.</p>

<p>Link to application:<a href="http://3.14.148.127:5000/DecadeStyles">DecadeStyles</a></p>

<h2 id="data-collection">Data Collection</h2>
<p>For this task, I wanted to build a clothing style classifier by decade. I could not find an existing dataset labeling attire style by decade, so I built one manually from Google images. Once this process was complete, I used transfer learning on a pre-trained deep-learning model to build my classifier.</p>

<h2 id="machine-learning">Machine Learning</h2>
<p>Since I was building an image classifier without tens of thousands of images, I used transfer learning. Transfer learning works off of a pre-trained model and replaces the final classification layers so as to apply it to a new set of images. Selecting the pre-trained model and structure of the final layers are hyperparameters to optimize on. In this case, I selected the VGG16 model with final layers of flatten, dropout (.75), and finally a dense layer (5, activation=softmax). The dropout layer was added to combat model overfitting. My selection process was manual, but advanced methods of Bayesian optimization and genetic algorithms can perform a more robust hyperparameter search. In this case, there was little marginal benefit of these methods because there was a cap on performance given the available data.</p>

<h2 id="results">Results</h2>
<p>The model achieved a categorical accuracy of 73% on the validation set. Accuracy is an appropriate performance metric since the categories were balanced. For more detail see the classification report below:</p>

<p><img src="http://localhost:4000/images/Classification_Report.png" alt="Image test" /></p>

<p>As this report shows, the major driver of error in the model is the 1940-1950s category, which has low recall (lots of false negatives).</p>

<h2 id="future-work">Future Work</h2>
<p>In addition to building a larger dataset, focusing on specific elements of clothing could achieve better results. For example, it would be powerful to train the machine to locate pant legs and identify bell bottoms, marking the style as 70s. With enough data, an ML algorithm would learn this on its own, but directed training achieves a better result with fewer images. Training a model to identify pant legs and collars is not trivial, and with time I can build on work that has been done in this area (see DeepFashion).</p>

<p>I could also further expand my data labels and training to other types of categories, like sub-cultures (hippie, punk) or levels of formality (semi-formal, business-casual) This model forms a nice base of work to expand on.</p>


  </article>
  
  <article class="post">
    <h1 class="post-title">
      <a href="/2019/03/25/Skytron/">
        Skytron
      </a>
    </h1>
    
    <time datetime="2019-03-25T00:00:00-07:00" class="post-date">25 Mar 2019</time>
    
    <hr />
<h2 id="overview">Overview</h2>
<p>Skytron was built to detect anomalous flight paths. However, it has a general use as a pipeline to analyze data as a stream and to train a model as a stream. Skytron learns to predict flight paths using the real-time data from the Open Sky Network. With the premise that anomalous flights will be harder to predict, the model logs anomalies based on prediction error.</p>

<h2 id="stream-vs-batch">Stream Vs Batch</h2>
<p>Skytron’s real-time anomaly detection allows immediate detection of problems and thus faster (cheaper) error correction. In the absence of historical data, rather than wait for a sufficiently sized batch you can hit the ground running and train off each piece of data as it comes in. This also saves on storage, because instead of requiring a large stored batch of training data, the model trains as a loop, continuously overwriting a small pool of data.</p>

<h2 id="training-loop">Training Loop</h2>
<p>The training loop makes an API call to the Open Sky Network collecting a flight vector (Longitude, Latitude, Altitude, Velocity, Heading) for every flight in the network; waits 10 seconds to collect a second set of vectors; then trains on the two sets; then predicts off the second set and overwrites the first for new set, evaluates prediction against new set, log errors, overwrites second set with newer set and repeats by training on the two new sets. To help clarify, see the diagram below.</p>

<p><img src="http://localhost:4000/images/stream-learn.png" alt="Image test" /></p>

<h2 id="threading">Threading</h2>
<p>While the training loop runs, I want to view current anomalies, extract a dictionary of all anomalies detected and extract the trained model once stable. I also want to display a streaming set of plots for model evaluation. Threading enables these process to run concurrently on the same set of variables. My diagram below may be helpful. Each box is an individual thread. I can extract from the Global variables in two ways…</p>

<p><img src="http://localhost:4000/images/tech-d.png" alt="Image test" /></p>

<h2 id="model">Model</h2>
<p>Skytron’s general framework is simple and modular, so it can be applied to various applications. For example, I could use a tensor instead of a vector and convolutional neural net instead of a multilayer perceptron to detect anomalies in video streams instead of flight paths. One thing that shouldn’t change is the use of a neural net. Otherwise, we need a function comparing deviation in say latitude compared to deviation velocity. A neural net saves us from this, because its algorithm, backpropagation, will not optimize for one variable over another, so the errors will be on similar scales. We can then reasonably take an average of errors for each prediction and use it to check for anomalies.</p>

<p><img src="http://localhost:4000/images/model.png" alt="Image test" /></p>

<h2 id="streaming-model-evaluation-plots">Streaming Model Evaluation Plots</h2>
<p>With streaming data, there is no classic train test split because were are not waiting around for batches to accumulate and worse we don’t have data labels. To evaluate the model, I created two live streaming plots and then judged if the results matched expectations. Below, at the early stage, the model is unstable with high error. I am not confident. Later, the model stabilizes and there is less variance in the anomalies detected. I have more confidence. The results still do not make perfect sense, there were not 1,000 anomalous flights, at least in a meaningful sense. This could be an artifact of the anomaly criterion being just one standard deviation. If I used three, the result might be more in line with what I am looking for.</p>

<p><img src="http://localhost:4000/images/plots2.png" alt="Image test" /></p>

<h2 id="future-work">Future Work</h2>
<ul>
  <li>Add the ability to run multiple models at once, select for the best performing model.</li>
  <li>Be able to tune anomaly criteria, in certain cases we might want to catch more or fewer anomalies</li>
  <li>Test on a different kind of data stream with a different neural net. Ex. Golf swing video</li>
</ul>

  </article>
  
</div>

<div class="pagination">
  
    <a class="pagination-item older" href="/page2">Older</a>
  
  
    <span class="pagination-item newer">Newer</span>
  
</div>

      </main>

      <footer class="footer">
        <small>
          <!--
          &copy; <time datetime="2019-05-01T13:44:21-07:00">2019</time>. All rights reserved.
        -->
        </small>
      </footer>
    </div>

    
  </body>
</html>
